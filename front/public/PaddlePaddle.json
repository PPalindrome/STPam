#####PaddlePaddle飞桨示例
# -*- coding: utf-8 -*-
import os
import numpy as np
import paddle.fluid as fluid

from paddle.distributed import fleet
import paddle

paddle.enable_static()


def mlp(input_x, input_y, hid_dim=1280, label_dim=2):
fc_1 = fluid.layers.fc(input=input_x, size=hid_dim, act='tanh')
fc_2 = fluid.layers.fc(input=fc_1, size=hid_dim, act='tanh')
prediction = fluid.layers.fc(input=[fc_2], size=label_dim, act='softmax')
cost = fluid.layers.cross_entropy(input=prediction, label=input_y)
avg_cost = fluid.layers.mean(x=cost)
return avg_cost


def gen_data():
return {"x": np.random.random(size=(128, 32)).astype('float32'),
"y": np.random.randint(2, size=(128, 1)).astype('int64')}

input_x = fluid.layers.data(name="x", shape=[32], dtype='float32')
input_y = fluid.layers.data(name="y", shape=[1], dtype='int64')


cost = mlp(input_x, input_y)
optimizer = fluid.optimizer.SGD(learning_rate=0.01)


dist_strategy = fleet.DistributedStrategy()
fleet.init(strategy=dist_strategy)


optimizer = fleet.distributed_optimizer(optimizer)
optimizer.minimize(cost, fluid.default_startup_program())

train_prog = paddle.static.default_main_program()

# 获得当前gpu的id号
gpu_id = int(os.getenv("FLAGS_selected_gpus", "0"))
print(gpu_id)
place = fluid.CUDAPlace(gpu_id)

exe = paddle.static.Executor(place)
exe.run(paddle.static.default_startup_program())

step = 100
for i in range(step):
cost_val = exe.run(program=train_prog, feed=gen_data(), fetch_list=[cost.name])
print("step%d cost=%f" % (i, cost_val[0]))

# 4: 模型保存
model_path = "./tmp"
if os.path.exists(model_path):
paddle.static.save(train_prog, model_path)