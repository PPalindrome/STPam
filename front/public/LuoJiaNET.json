#####LuoJiaNET示例
#####更多分布式要求参考https://whu.obs.cn-central-221.ovaijisuan.com/instruction/intermediate/distributed_training/distributed_training_gpu.html

###配置分布式环境
#OpenMPI-4.0.3：LuoJiaNET采用的多进程通信库。
#NCCL-2.7.6：Nvidia集合通信库。

###调用集合通信库
#在GPU硬件平台上，LuoJiaNET分布式并行训练的通信使用的是NCCL。 同时，LuoJiaNET可加入一行代码: context.set_auto_parallel_context(parallel_mode=context.ParallelMode.AUTO_PARALLEL)， 指定自动并行模式，获取设备的最优并行能力。
#下面是调用自动并行的代码样例：

from luojianet_ms import context
from luojianet_ms.communication import init

if __name__ == "__main__":
context.set_context(mode=context.GRAPH_MODE, device_target="GPU")
context.set_auto_parallel_context(parallel_mode=context.ParallelMode.AUTO_PARALLEL)
init("nccl")
#...

#其中，
#mode=context.GRAPH_MODE：使用分布式训练需要指定运行模式为图模式。
#init("nccl")：使能NCCL通信，并完成分布式训练初始化操作。

#!/bin/bash
mkdir device
mpirun -n 8 pytest -s -v ./resnet50_distributed_training.py > train.log 2>&1 &
#脚本会在后台运行，日志文件会保存到device目录下，共跑了10个epoch，每个epoch有234个step，关于Loss部分结果保存在train.log中。选取部分示例，如下：
epoch: 1 step: 1, loss is 2.3025854
epoch: 1 step: 1, loss is 2.3025854
epoch: 1 step: 1, loss is 2.3025854
epoch: 1 step: 1, loss is 2.3025854
epoch: 1 step: 1, loss is 2.3025854
epoch: 1 step: 1, loss is 2.3025854
epoch: 1 step: 1, loss is 2.3025854
epoch: 1 step: 1, loss is 2.3025854